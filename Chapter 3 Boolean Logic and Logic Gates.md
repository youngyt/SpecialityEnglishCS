We have talked about how computers evolved from electromechanical devices, that often had decimal representations of numbers- like those represented by teeth on a gear- to electronic computers with [[transistors]] that can turn the flow of electricity on or off. And fortunately, even with just two states of electricity, we can represent important information.

We call this representation **[[Binary]]** - which **[[literally]]** means "of two states", in the same way a bicycle has two wheels or a biped has two legs. You might think two states isn't a lot to work with, and you'd be right! But, it's exactly what you need for representing the values "true" and "false". In computers, an "on" state, when electricity is flowing, represents _true_. The "off" state, no electricity flowing, represents _false_. We can also write binary as 1's and 0's instead of true's and false's , which are just different expressions of the same signal. Now it is actually possible to use transistors for more than just turning electrical current on and off, and to allow for different levels of current.

Some early electronic computers were **[[ternary]]**, that's three states, and even **quinary**, using 5 states. The problem is, the more intermediate states there are, the harder it is to keep them all separate. So, placing two signals as far **[[apart]]** as possible- using just 'on and off' - gives us the most **[[distinct]]** signal to **[[minimize]]** these **[[issues]]**.

Another reason computers use binary is that an **[[entire]]** branch of mathematics already existed that dealt **[[exclusively]]** with true and false values. And it had figured out all of the necessary rules and operations for manipulating them. It's called **[[Boolean Algebra]]**! **_George Boole_**, from which Boolean Algebra later got its [name](a), was a self-taught English mathematician in the 1800s. He was interested in representing **logical** **[[statements]]** that went "*under, over, and beyond*" Aristotle's approach to logic, which was, **[[unsurprisingly]]**, **[[grounded]]** in philosophy. Boole's approach allowed truth to be **[[systematically]]** and **[[formally]]** proven, through logic **[[equations]]** which he introduced in his first book, "_The Mathematical Analysis of Logic_" in 1847. In "regular" algebra, the values of variables are numbers, and operations on those numbers are things like addition and multiplication. But in Boolean Algebra, the values of variables are true and false, and the operations are logical.

There are three fundamental operations in Boolean Algebra: a NOT, an AND, and an OR operation. A NOT takes a single Boolean value, either true or false, and negates it. It **[[flips]]** true to false, and false to true. We can write out a little **logic table** that shows the original value under Input, and the outcome after applying the operation under Output.  

We can easily build Boolean logic out of transistors. The transistors have three wires: two electrodes and one control wire. When you apply electricity to the control wire, it lets current flow through from one electrode, through the transistor, to the other electrode. You can think of the control wire as an input, and the wire coming from the bottom electrode as the output. So with a single transistor, we have one input and one output. If we turn the input on, the output is also on because the current can flow through it. If we turn the input off, the output is also off and the current can no longer pass through. Or in Boolean terms, when the input is true, the output is true. And when the input is false, the output is also false. This isn't a very exciting circuit though because it's not doing anything-- the input and output are the same. But we can **[[modify]]** this circuit just a little bit to create a **_[[NOT]]_**. **_Instead of having the output wire at the end of the transistor, we can move it before_**. If we turn the input on, the transistor allows current to pass through it to the "ground", and the output wire won't receive that current- so it will be off. So in this case if the input is on, output is off. When we turn off the transistor, though, current is prevented from flowing down it to the ground, so instead, current flows through the output wire. So the input will be off and the output will be on. We call this circuit as **NOT gate** - we call them gates because they're controlling the path of our current.

---

The AND Boolean operation takes two inputs, but still has a single output. In this case the output is only true if both inputs are true. To build an **[[AND gate]]**, we need two transistors connected together so we have our two inputs and one output. If we turn on just transistor A, current won't flow because the current is stopped by transistor B. Alternatively, if transistor B is on, but the transistor A is off, the same thing, the current can't get through. Only if transistor A AND transistor B are on does the output wire have current.

The last Boolean operation is OR-- where only one input has to be true for the output to be true. The only time an OR statement is false is if both inputs are false. Building an **[[OR gate]]** from transistors needs a few extra wires. Instead of having two transistors in series -- one after the other --we have them in parallel. We run wires from the current source to both transistors. If both transistors are turned off, the current is prevented from flowing to the output, so the output is also off. Now, if we turn on just Transistor A, current can flow to the output. Same thing if transistor A is off, but Transistor B in on. Basically if A OR B is on, the output is also on. Also, if both transistors are on, the output is still on.

Now we've got NOT, AND, and OR gates, and we can leave behind the constituent transistors and move up a layer of abstraction. _The standard engineers use for these gates are a triangle with a dot for a NOT, a D for the AND, and a spaceship for the OR._

Another useful Boolean operation in computation is called an **[[Exclusive OR]]**- or **[[XOR]]** for short. XOR is like a regular OR, but with one difference: if both inputs are true, the XOR is false. The only time an XOR is true is when one input is true and the other input is false. It's like when you go out to dinner and your meal comes with a side salad OR a soup- sadly, you can't have both! And building this from transistors is pretty confusing, but we can show how an XOR is created from our three basic Boolean gates. XOR turns out to be a very useful component and engineers gave it its own symbol too -- _an OR gate with a smile :)_. But most importantly, we can now put XOR into our **[[metaphorical]]** toolbox and not have to worry about the individual logic gates that make it up or the transistors that make up those gates, or how electrons are flowing through a semiconductor.

When computer engineers are designing processors, they rarely work at the transistor level and instead work with much larger blocks, like logic gates, and even larger components made up of logic gates. And even if you are a professional computer programmer, it's not often that you think about how the logic that you are programming is actually **[[implemented]]** in the physical world by these **teeny** **tiny** components.